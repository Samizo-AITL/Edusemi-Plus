# 第2章：AIの歴史とブームの背景

## 2.1 初期のAIとその限界

人工知能（AI）の研究は1950年代に端を発します。  
当初は論理推論やルールベースのエキスパートシステムが主流で、特定の分野では実用化も試みられました。

- **1956年：ダートマス会議**  
  「Artificial Intelligence」という用語が初めて提唱される。
- **1980年代：エキスパートシステムの台頭**  
  医療・製造などへの応用が進むが、運用コストやスケーラビリティの課題が顕在化。
- その結果、AIへの過度な期待が失望に転じ、**「AIの冬」**と呼ばれる停滞期が二度訪れた。

> 初期AIはルール駆動型であり、柔軟性や学習能力に乏しかった。

---

## 2.2 深層学習の登場とGPUの台頭

2006年、Hintonらの研究により「深層学習（Deep Learning）」が再評価され始め、  
2012年のImageNetコンペにて**AlexNet**が圧倒的な成績を収めたことで、AIは新たな転機を迎えました。

### 🔑 技術的ブレイクスルー

- **演算性能の壁を打破**するため、並列演算に優れた **GPU** が活用され始める。
- アルゴリズム面では、**ReLU, Dropout, BatchNorm** などの工夫により学習効率が向上。
- **大量データ × 高性能計算 × 高度なアルゴリズム** の三位一体が成果に直結。

> GPUはもともとグラフィックス用だったが、深層学習に最適な汎用アクセラレータとして再定義された。

---

## 2.3 現在のブームと大規模言語モデル（LLM）

2020年代に入り、AIの主戦場は画像認識から自然言語処理へと拡大。  
中でも、**大規模言語モデル（LLM）**はAIの認知能力を飛躍的に高め、ブームの中核となっています。

### 🌍 LLMの特徴と要件

- 代表例：**GPT-4（OpenAI）**、**Claude（Anthropic）**、**Gemini（Google）**
- パラメータ数は **数千億〜数兆規模** に到達。
- トレーニングには **莫大な演算量・ストレージ・電力** が必要。
- 推論においても **レイテンシ・帯域・消費電力** がボトルネックとなる。

### 💡 ハードウェア依存の高まり

- モデルの性能向上には、**専用アクセラレータ（GPU, TPU, ASICなど）** が不可欠。
- LLMは、**ソフトウェアとハードウェアの共進化**の象徴である。

---

## 2.4 参入企業の多様化と市場拡大

AI市場の拡大に伴い、計算インフラの重要性が増し、  
多くの企業が **AI専用ハードウェアの開発競争** に参入しています。

| 企業 | 戦略・特徴 |
|------|------------|
| **NVIDIA** | GPU主導のAI計算市場を確立。CUDAで開発エコシステムを囲い込み。 |
| **Google** | TPUを設計し、クラウドAI処理の効率化を追求。 |
| **Apple** | スマートフォン向けNeural Engineを自社SoCに統合。 |
| **AMD** | MIシリーズでデータセンターAI市場を狙う。 |
| **Intel** | Habana LabsやNervanaなどの買収を通じAI強化。 |
| **Cerebras, Groq, Tenstorrent** | LLM・推論特化の新興AIチップ企業。極端な性能追求で差別化。 |

> AIブームは、ソフトウェア革新だけでなく「ハードウェア主導のイノベーション競争」としても展開されている。

---

## ✅ 本章のまとめ

- AIは1950年代から数度のブームと冬を繰り返し、**深層学習の復活とGPUの台頭**で飛躍を遂げた。  
- 現在は、**大規模言語モデル（LLM）**とそれを支える**演算インフラの革新**がブームを加速させている。  
- 多くの企業がAIハードウェア開発に参入し、**技術・市場・競争の焦点が半導体へとシフト**している。
