# 第2章：AIの歴史とブームの背景

## 2.1 初期のAIと限界

人工知能の研究は1950年代に始まり、初期のエキスパートシステムやルールベースの推論が開発されました。  
しかし、計算資源とアルゴリズムの制約により、期待された成果は得られず「AIの冬」と呼ばれる停滞期が訪れます。

- 1956年：ダートマス会議で「人工知能」という用語が初登場  
- 1980年代：エキスパートシステムの流行 → 限界を露呈し、2度目の冬へ

## 2.2 深層学習の登場とGPUの台頭

2006年頃、深層学習（Deep Learning）の再評価が始まりました。  
特に2012年、ImageNetコンペでディープニューラルネット（AlexNet）が従来の手法を圧倒したことが転機となりました。

- 計算に適したハードウェアとして**GPU**が注目される  
- 学習アルゴリズムの改良（ReLU、Dropout、BatchNormなど）  
- 大量データ＋高性能計算資源の融合がブレイクスルーに

## 2.3 現在のブームと大規模言語モデル（LLM）

現在のAIブームは、**大規模言語モデル（LLM）**の登場によりさらに加速しています。

- **GPT系モデル（OpenAI）**や**Claude（Anthropic）**などに代表されるLLMは、数千億〜数兆パラメータ規模
- トレーニングには膨大な計算資源と時間、**専用ハードウェア**（GPU/TPU/ASIC）が不可欠
- 推論でも電力効率とメモリ帯域がボトルネック

## 2.4 参画企業の増加と市場の拡大

AIがイノベーションの中核となることで、ハードウェア開発に乗り出す企業が急増しています。

| 企業        | 戦略・特徴                             |
|-------------|----------------------------------------|
| NVIDIA      | GPU主導のAIブーム、CUDAによる囲い込み |
| Google      | TPUによるクラウドAI最適化             |
| Apple       | モバイル向けNeural Engine             |
| AMD         | データセンター向けMIシリーズ           |
| Intel       | Habana Labsなど買収でAI強化           |
| Groq, Tenstorrent, Cerebras | 新興AIチップ設計企業     |

---

現在のAIブームは、単なるソフトウェア革新ではなく、**ハードウェアと計算インフラの競争**でもあります。
AIが支える半導体産業の構造は、この10年で大きく塗り替えられつつあります。
