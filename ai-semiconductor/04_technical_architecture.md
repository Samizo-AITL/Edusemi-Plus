# 第4章：AI半導体の技術概要

## 4.1 AI処理における計算の特徴

深層学習をはじめとするAI処理では、以下のような**演算負荷の高い処理**が繰り返し行われます：

- **大規模行列／テンソル演算**（GEMM、Convolutionなど）  
- **学習（Training）**：誤差逆伝播、勾配計算、パラメータ更新  
- **推論（Inference）**：低レイテンシ・リアルタイム処理、電力効率の確保

これらを高効率に処理するために、**汎用CPUとは異なる専用アーキテクチャ**が求められ、  
AI半導体市場の多様化を生んでいます。

---

## 4.2 主なAIアーキテクチャとその特性

### ✅ GPU（Graphics Processing Unit）
- **開発背景**：元は3Dグラフィックス処理向け  
- **構造**：数千スレッド単位のSIMD型並列演算  
- **用途**：学習・推論ともに広く活用。CUDA、cuDNNなどソフト環境が充実  
- **代表例**：NVIDIA A100 / H100, AMD MI300 など

> GPUは「汎用性のあるAIアクセラレータ」として、AI黎明期から市場を牽引してきた。

---

### ✅ TPU（Tensor Processing Unit：Google）
- **特徴**：行列積演算（MAC）に特化。Systolic Array構造、Bfloat16などを採用  
- **用途**：Google Cloudの内部推論／訓練処理に最適化  
- **設計思想**：高密度・低レイテンシ・演算効率重視のハード×ソフト共設計  
- **代表例**：TPU v4, v5e

> Google独自設計により、特定モデルに対する計算効率を最大化。

---

### ✅ NPU（Neural Processing Unit）
- **特徴**：エッジAI用途に特化した小型・省電力AIプロセッサ  
- **用途**：画像認識／音声処理／ARジェスチャー制御などのリアルタイム処理  
- **技術ポイント**：SoCへの統合、MAC演算回路の最適化、DRAM帯域の最小化  
- **代表例**：Apple Neural Engine, Huawei Ascend, Qualcomm Hexagon

> 「スマホの中のAIチップ」として一般消費者向け製品にも普及。

---

### ✅ ASIC（Application Specific IC）
- **特徴**：用途特化の完全カスタム設計により、極限の性能最適化が可能  
- **用途**：LLM推論や研究向け大規模演算、高性能用途に多い  
- **課題**：開発コストが高く、汎用性が低い  
- **代表例**：Cerebras WSE、GroqChip、Tenstorrentなど

> 限定用途において、汎用アーキテクチャを凌駕する性能を発揮。

---

## 4.3 LLM（大規模言語モデル）とハードウェア要件

大規模言語モデル（LLM）は、従来のAIモデルを遥かに上回る**計算資源・帯域・電力**を必要とします。

### 🔍 LLM処理の技術的要求

- 数千億〜数兆パラメータ  
- 長文トークン処理における**Self-Attention**がボトルネック  
- 分散処理・並列演算・精度制御の組合せが性能の鍵

### 💡 ハードウェア設計のポイント

| 領域 | 最適化技術 |
|------|-------------|
| 行列演算 | MACユニットの並列配置、可変精度（FP8, BF16） |
| メモリ | HBM, SRAM、オンチップメモリ、チップレット構成 |
| インターコネクト | NVLink, Infinity Fabric, PCIe Gen5 |
| 電力最適化 | Dynamic Voltage Scaling、アクティブ電力制御など |

---

## 4.4 ソフトウェアとの共設計：AI時代の新常識

AI半導体は**ハードウェアとソフトウェアの協調設計（co-design）**が前提となっています。

### 代表的要素：

- **コンパイラと中間表現（IR）**：XLA, MLIR, TVM などで最適なコード生成  
- **EDAツールとの融合**：AI回路設計をEDA自動化で支援（Synopsys DSO.ai 等）  
- **フレームワーク最適化**：TensorFlow, PyTorch, ONNX対応と各チップの統合性  
- **モデルチューニング**：事前学習済みモデルごとに特化した最適パスの導出

> ハード単体での性能ではなく、「ソフトウェアとの統合性能」が今後の競争軸となる。

---

## ✅ 本章のまとめ

- AI処理の特性に合わせて、GPU／TPU／NPU／ASIC などの**多様なアーキテクチャ**が並存  
- LLM時代には、**高帯域・低レイテンシ・演算密度・省電力**のバランスが要求される  
- 今後のAI半導体は、ソフトウェアとの**一体的な最適化（共設計）**によって進化していく
